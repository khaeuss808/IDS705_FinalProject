{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import (\n",
    "    BertTokenizer,\n",
    "    BertForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading/exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When I remember her I feel down</td>\n",
       "      <td>Emotional pain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I carry heavy things I feel like breaking...</td>\n",
       "      <td>Hair falling out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is too much pain when i move my arm</td>\n",
       "      <td>Heart hurts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My son had his lip pierced and it is swollen a...</td>\n",
       "      <td>Infected wound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My muscles in my lower back are aching</td>\n",
       "      <td>Infected wound</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              phrase             label\n",
       "0                    When I remember her I feel down    Emotional pain\n",
       "1  When I carry heavy things I feel like breaking...  Hair falling out\n",
       "2          there is too much pain when i move my arm       Heart hurts\n",
       "3  My son had his lip pierced and it is swollen a...    Infected wound\n",
       "4             My muscles in my lower back are aching    Infected wound"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"overview-of-recordings.csv\")\n",
    "df = df[[\"phrase\", \"prompt\"]]\n",
    "# i want it to be called phrase, label for column names\n",
    "df = df.rename(columns={\"phrase\": \"phrase\", \"prompt\": \"label\"})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6661, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "Acne                  328\n",
       "Shoulder pain         320\n",
       "Joint pain            318\n",
       "Infected wound        306\n",
       "Knee pain             305\n",
       "Cough                 293\n",
       "Feeling dizzy         283\n",
       "Muscle pain           282\n",
       "Heart hurts           273\n",
       "Ear ache              270\n",
       "Hair falling out      264\n",
       "Head ache             263\n",
       "Feeling cold          263\n",
       "Skin issue            262\n",
       "Stomach ache          261\n",
       "Back pain             259\n",
       "Neck pain             251\n",
       "Internal pain         248\n",
       "Blurry vision         246\n",
       "Body feels weak       241\n",
       "Hard to breath        233\n",
       "Emotional pain        231\n",
       "Injury from sports    230\n",
       "Foot ache             223\n",
       "Open wound            208\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phrase</th>\n",
       "      <th>label</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When I remember her I feel down</td>\n",
       "      <td>Emotional pain</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I carry heavy things I feel like breaking...</td>\n",
       "      <td>Hair falling out</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>there is too much pain when i move my arm</td>\n",
       "      <td>Heart hurts</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My son had his lip pierced and it is swollen a...</td>\n",
       "      <td>Infected wound</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My muscles in my lower back are aching</td>\n",
       "      <td>Infected wound</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              phrase             label  \\\n",
       "0                    When I remember her I feel down    Emotional pain   \n",
       "1  When I carry heavy things I feel like breaking...  Hair falling out   \n",
       "2          there is too much pain when i move my arm       Heart hurts   \n",
       "3  My son had his lip pierced and it is swollen a...    Infected wound   \n",
       "4             My muscles in my lower back are aching    Infected wound   \n",
       "\n",
       "   label_id  \n",
       "0         0  \n",
       "1         1  \n",
       "2         2  \n",
       "3         3  \n",
       "4         3  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this creates an integer for each label\n",
    "# creates column label_id with the number label for each of the labels\n",
    "\n",
    "unique_labels = df[\"label\"].unique().tolist()\n",
    "label2id = {label: i for i, label in enumerate(unique_labels)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "df[\"label_id\"] = df[\"label\"].map(label2id)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, test, validation split\n",
    "# adjust to 80/20 or whatever as needed\n",
    "train_df, test_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now coverting the pandas dataframes into Hugging Face dataset objects\n",
    "train_dataset = Dataset.from_pandas(train_df[[\"phrase\", \"label_id\"]])\n",
    "val_dataset = Dataset.from_pandas(val_df[[\"phrase\", \"label_id\"]])\n",
    "test_dataset = Dataset.from_pandas(test_df[[\"phrase\", \"label_id\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"phrase\"], padding=\"max_length\", truncation=True, max_length=128\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca1ee96b46d4971b52e983a547cf9eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2040f5d761bd4e389913961ac186c1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1066 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "374ee5e7b7fd4d73953013f3c46d4825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1333 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# apply the tokenizer to our data\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "val_dataset = val_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# rename columns to the format Trainer expects\n",
    "train_dataset = train_dataset.rename_column(\"label_id\", \"labels\")\n",
    "val_dataset = val_dataset.rename_column(\"label_id\", \"labels\")\n",
    "test_dataset = test_dataset.rename_column(\"label_id\", \"labels\")\n",
    "\n",
    "# set format to PyTorch tensors\n",
    "train_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "val_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "test_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=len(unique_labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kaylahaeusssler/miniforge3/lib/python3.12/site-packages/transformers/training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/var/folders/bs/tlrmg2n164520pry59rs7fvh0000gn/T/ipykernel_61797/2793559272.py:24: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca34e989dd7463994bb1b693f306a15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1599 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0871, 'grad_norm': 8.741687774658203, 'learning_rate': 4.843652282676673e-05, 'epoch': 0.09}\n",
      "{'loss': 2.4788, 'grad_norm': 11.904923439025879, 'learning_rate': 4.687304565353346e-05, 'epoch': 0.19}\n",
      "{'loss': 1.6697, 'grad_norm': 8.758871078491211, 'learning_rate': 4.530956848030019e-05, 'epoch': 0.28}\n",
      "{'loss': 1.0783, 'grad_norm': 4.06333065032959, 'learning_rate': 4.374609130706692e-05, 'epoch': 0.38}\n",
      "{'loss': 0.7145, 'grad_norm': 2.2248008251190186, 'learning_rate': 4.218261413383365e-05, 'epoch': 0.47}\n",
      "{'loss': 0.4453, 'grad_norm': 8.431148529052734, 'learning_rate': 4.061913696060038e-05, 'epoch': 0.56}\n",
      "{'loss': 0.4056, 'grad_norm': 11.223329544067383, 'learning_rate': 3.905565978736711e-05, 'epoch': 0.66}\n",
      "{'loss': 0.2482, 'grad_norm': 1.8804333209991455, 'learning_rate': 3.7492182614133836e-05, 'epoch': 0.75}\n",
      "{'loss': 0.1907, 'grad_norm': 1.1005831956863403, 'learning_rate': 3.5928705440900565e-05, 'epoch': 0.84}\n",
      "{'loss': 0.16, 'grad_norm': 0.39669471979141235, 'learning_rate': 3.4365228267667294e-05, 'epoch': 0.94}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d88455e1e0b4f8a8e04811846b8255d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.1228461042046547, 'eval_accuracy': 0.9718574108818011, 'eval_f1': 0.9716585743470921, 'eval_runtime': 5.5426, 'eval_samples_per_second': 192.328, 'eval_steps_per_second': 24.176, 'epoch': 1.0}\n",
      "{'loss': 0.1221, 'grad_norm': 0.2567582130432129, 'learning_rate': 3.2801751094434024e-05, 'epoch': 1.03}\n",
      "{'loss': 0.0658, 'grad_norm': 0.14377978444099426, 'learning_rate': 3.123827392120075e-05, 'epoch': 1.13}\n",
      "{'loss': 0.0648, 'grad_norm': 0.3524585962295532, 'learning_rate': 2.9674796747967482e-05, 'epoch': 1.22}\n",
      "{'loss': 0.0368, 'grad_norm': 0.14718036353588104, 'learning_rate': 2.811131957473421e-05, 'epoch': 1.31}\n",
      "{'loss': 0.0475, 'grad_norm': 0.10879917442798615, 'learning_rate': 2.6547842401500937e-05, 'epoch': 1.41}\n",
      "{'loss': 0.0515, 'grad_norm': 0.19178684055805206, 'learning_rate': 2.4984365228267666e-05, 'epoch': 1.5}\n",
      "{'loss': 0.0093, 'grad_norm': 0.07616429030895233, 'learning_rate': 2.34208880550344e-05, 'epoch': 1.59}\n",
      "{'loss': 0.0267, 'grad_norm': 0.06863011419773102, 'learning_rate': 2.1857410881801128e-05, 'epoch': 1.69}\n",
      "{'loss': 0.0215, 'grad_norm': 0.05573077127337456, 'learning_rate': 2.0293933708567854e-05, 'epoch': 1.78}\n",
      "{'loss': 0.046, 'grad_norm': 0.06165880337357521, 'learning_rate': 1.8730456535334583e-05, 'epoch': 1.88}\n",
      "{'loss': 0.0658, 'grad_norm': 0.0448187030851841, 'learning_rate': 1.7166979362101316e-05, 'epoch': 1.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f529402e764d71b6adbbe336e2acee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.03994685038924217, 'eval_accuracy': 0.9934333958724203, 'eval_f1': 0.9934230807086855, 'eval_runtime': 5.4781, 'eval_samples_per_second': 194.593, 'eval_steps_per_second': 24.461, 'epoch': 2.0}\n",
      "{'loss': 0.0081, 'grad_norm': 0.05965210869908333, 'learning_rate': 1.5603502188868045e-05, 'epoch': 2.06}\n",
      "{'loss': 0.0149, 'grad_norm': 0.060965802520513535, 'learning_rate': 1.4040025015634772e-05, 'epoch': 2.16}\n",
      "{'loss': 0.0255, 'grad_norm': 0.038357894867658615, 'learning_rate': 1.2476547842401502e-05, 'epoch': 2.25}\n",
      "{'loss': 0.0217, 'grad_norm': 0.046150092035532, 'learning_rate': 1.0913070669168231e-05, 'epoch': 2.35}\n",
      "{'loss': 0.005, 'grad_norm': 0.03978721424937248, 'learning_rate': 9.34959349593496e-06, 'epoch': 2.44}\n",
      "{'loss': 0.0176, 'grad_norm': 0.049604762345552444, 'learning_rate': 7.78611632270169e-06, 'epoch': 2.53}\n",
      "{'loss': 0.0238, 'grad_norm': 0.030209306627511978, 'learning_rate': 6.222639149468418e-06, 'epoch': 2.63}\n",
      "{'loss': 0.0448, 'grad_norm': 0.04170714318752289, 'learning_rate': 4.659161976235147e-06, 'epoch': 2.72}\n",
      "{'loss': 0.0429, 'grad_norm': 1.9396865367889404, 'learning_rate': 3.095684803001876e-06, 'epoch': 2.81}\n",
      "{'loss': 0.0423, 'grad_norm': 0.06906791031360626, 'learning_rate': 1.5322076297686055e-06, 'epoch': 2.91}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94d990d35e1a4c39a6dd46f5b4b2eda0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.031215321272611618, 'eval_accuracy': 0.9934333958724203, 'eval_f1': 0.9934230807086855, 'eval_runtime': 6.2693, 'eval_samples_per_second': 170.035, 'eval_steps_per_second': 21.374, 'epoch': 3.0}\n",
      "{'train_runtime': 276.4993, 'train_samples_per_second': 46.242, 'train_steps_per_second': 5.783, 'train_loss': 0.3532891169870698, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1599, training_loss=0.3532891169870698, metrics={'train_runtime': 276.4993, 'train_samples_per_second': 46.242, 'train_steps_per_second': 5.783, 'total_flos': 841208168572416.0, 'train_loss': 0.3532891169870698, 'epoch': 3.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# defining the training hyperparams\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",  # Evaluate every epoch\n",
    "    save_strategy=\"epoch\",  # Save checkpoint every epoch\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,  # Adjust based on dataset size\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "\n",
    "# evaluation function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "\n",
    "# initialize the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# now we actually trian\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6217c43ced24dc29420f1a5be092629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/134 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {'eval_loss': 0.031215321272611618, 'eval_accuracy': 0.9934333958724203, 'eval_f1': 0.9934230807086855, 'eval_runtime': 5.5163, 'eval_samples_per_second': 193.246, 'eval_steps_per_second': 24.292, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8cf859e9a44b218b11643c4a7124b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/167 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test metrics: {'eval_loss': 0.0228365957736969, 'eval_accuracy': 0.994748687171793, 'eval_f1': 0.9947237734422149, 'eval_runtime': 6.9094, 'eval_samples_per_second': 192.927, 'eval_steps_per_second': 24.17, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "val_metrics = trainer.evaluate(eval_dataset=val_dataset)\n",
    "print(\"Validation metrics:\", val_metrics)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics = trainer.evaluate(eval_dataset=test_dataset)\n",
    "print(\"Test metrics:\", test_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
